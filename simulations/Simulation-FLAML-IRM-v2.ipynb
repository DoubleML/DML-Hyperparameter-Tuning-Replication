{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd5f0eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import doubleml as dml\n",
    "import numpy as np\n",
    "from flaml import AutoML\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, log_loss\n",
    "from ..doubleml_flaml_api.doubleml_flaml_api import FlamlRegressorDoubleML, FlamlClassifierDoubleML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f624843c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_folds = 4\n",
    "no_iter = 100\n",
    "scenarios = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16]\n",
    "for sc in scenarios:\n",
    "    res_path = f\"../results/acic/irm/Scenario{sc}/\"\n",
    "    for t in [1,4,7,10,20,40,60]:\n",
    "        res_fullsample = []\n",
    "        res_splitsample = []\n",
    "        res_onfolds = []\n",
    "        for k in range(no_iter):\n",
    "            # for saving each iteration\n",
    "            _res_full = []\n",
    "            _res_split = []\n",
    "            _res_of = []\n",
    "            \n",
    "            #load data\n",
    "            df = pd.read_csv(f\"../dgp/acic/Scenario{sc}/CHDScenario{sc}DS{k+1}.csv\")\n",
    "            y, d, X = df[\"Y\"], df[\"A\"], df.drop(columns=[\"Y\",\"A\"])\n",
    "            \n",
    "            \n",
    "            # full sample, tuning\n",
    "            while True:\n",
    "                try:\n",
    "                    automl_y = AutoML()\n",
    "                    automl_y.fit(df.drop(columns=[\"Y\"]), y, task=\"regression\", time_budget=t, metric=\"mse\", verbose=False, estimator_list = None)\n",
    "                    automl_d = AutoML()\n",
    "                    automl_d.fit(X, d, task=\"classification\", time_budget=t, metric=\"log_loss\", verbose=False, estimator_list = None)\n",
    "            \n",
    "                    ml_g = automl_y.model.estimator\n",
    "                    ml_m = automl_d.model.estimator\n",
    "                    break\n",
    "                except AttributeError:\n",
    "                    pass\n",
    "                    \n",
    "            # full sample, doubleml\n",
    "            np.random.seed(k)\n",
    "            obj_dml_data = dml.DoubleMLData(df,y_col='Y',d_cols='A')\n",
    "            dml_irm_automl = dml.DoubleMLIRM(obj_dml_data, ml_g = ml_g, ml_m = ml_m, n_folds = n_folds, trimming_threshold=0.025)\n",
    "            dml_irm_automl.fit(store_predictions=True)\n",
    "        \n",
    "            _res_full.append(dml_irm_automl.summary[\"coef\"].values[0])\n",
    "            _res_full.append(dml_irm_automl.summary[\"2.5 %\"].values[0])\n",
    "            _res_full.append(dml_irm_automl.summary[\"97.5 %\"].values[0])\n",
    "            _res_full.append(automl_y.best_loss)\n",
    "            _res_full.append(automl_d.best_loss)\n",
    "            treat_ind = (df[\"A\"] == 1)\n",
    "            ml_g_pred = treat_ind * dml_irm_automl.predictions[\"ml_g1\"][:,0,0] + (1 - treat_ind) * dml_irm_automl.predictions[\"ml_g0\"][:,0,0]\n",
    "            _res_full.append(mean_squared_error(y, ml_g_pred))\n",
    "            _res_full.append(log_loss(d, dml_irm_automl.predictions[\"ml_m\"][:,0,0]))\n",
    "            \n",
    "            \n",
    "            # split sample, tuning\n",
    "            df_tune, df_test = train_test_split(df, test_size= 0.5, random_state = 42)\n",
    "            y_tune, d_tune, X_tune = df_tune[\"Y\"], df_tune[\"A\"], df_tune.drop(columns=[\"Y\",\"A\"])\n",
    "            \n",
    "            while True:\n",
    "                try:\n",
    "                    automl_y = AutoML()\n",
    "                    automl_y.fit(df_tune.drop(columns=[\"Y\"]), y_tune, task=\"regression\", time_budget=t, metric= \"mse\", verbose=False)\n",
    "                    automl_d = AutoML()\n",
    "                    automl_d.fit(X_tune, d_tune, task=\"classification\", time_budget=t, metric= \"log_loss\", verbose=False)\n",
    "            \n",
    "                    ml_g = automl_y.model.estimator\n",
    "                    ml_m = automl_d.model.estimator\n",
    "                    break\n",
    "                except AttributeError:\n",
    "                    pass\n",
    "\n",
    "            # split sample, doubleml\n",
    "            np.random.seed(2*k)\n",
    "            obj_dml_data = dml.DoubleMLData(df_test, y_col='Y', d_cols='A')\n",
    "            dml_irm_automl_split = dml.DoubleMLIRM(obj_dml_data, ml_g = ml_g, ml_m = ml_m, n_folds = n_folds, trimming_threshold=0.025)\n",
    "            dml_irm_automl_split.fit(store_predictions = True)\n",
    "\n",
    "            _res_split.append(dml_irm_automl_split.summary[\"coef\"].values[0])\n",
    "            _res_split.append(dml_irm_automl_split.summary[\"2.5 %\"].values[0])\n",
    "            _res_split.append(dml_irm_automl_split.summary[\"97.5 %\"].values[0])\n",
    "            _res_split.append(automl_y.best_loss)\n",
    "            _res_split.append(automl_d.best_loss)\n",
    "            treat_ind = (df_test[\"A\"] == 1)\n",
    "            ml_g_pred = treat_ind * dml_irm_automl_split.predictions[\"ml_g1\"][:,0,0] + (1 - treat_ind) * dml_irm_automl_split.predictions[\"ml_g0\"][:,0,0]\n",
    "            _res_split.append(mean_squared_error(df_test[\"Y\"], ml_g_pred))\n",
    "            _res_split.append(log_loss(df_test[\"A\"], dml_irm_automl_split.predictions[\"ml_m\"][:,0,0]))\n",
    "            \n",
    "            # onfolds, tuning\n",
    "            while True:\n",
    "                try:\n",
    "                    ml_g = FlamlRegressorDoubleML(time = (t/4), metric=\"mse\", estimator_list = None)\n",
    "                    ml_m = FlamlClassifierDoubleML(time = (t/4), metric=\"log_loss\", estimator_list = None)\n",
    "\n",
    "                    obj_dml_data = dml.DoubleMLData(df,y_col='Y',d_cols='A')\n",
    "            \n",
    "                    np.random.seed(3*k)\n",
    "                    dml_irm_automl_onfolds = dml.DoubleMLIRM(obj_dml_data, ml_g = ml_g, ml_m = ml_m, n_folds = n_folds, trimming_threshold=0.025)\n",
    "                    dml_irm_automl_onfolds.fit(store_predictions=True, store_models=True)\n",
    "                    break\n",
    "                except AttributeError:\n",
    "                    pass\n",
    "            \n",
    "            _res_of.append(dml_irm_automl_onfolds.summary[\"coef\"].values[0])\n",
    "            _res_of.append(dml_irm_automl_onfolds.summary[\"2.5 %\"].values[0])\n",
    "            _res_of.append(dml_irm_automl_onfolds.summary[\"97.5 %\"].values[0])\n",
    "            \n",
    "            treat_ind = (df[\"A\"] == 1)\n",
    "            fs_of_mlm, fs_of_mlg = 0,0\n",
    "            for i in range(n_folds):\n",
    "                fs_of_mlg += np.mean(treat_ind * dml_irm_automl_onfolds.models['ml_g1'][\"A\"][0][i].auto_ml.best_loss + (1 - treat_ind) * dml_irm_automl_onfolds.models['ml_g0'][\"A\"][0][i].auto_ml.best_loss)\n",
    "                fs_of_mlm += dml_irm_automl_onfolds.models['ml_m'][\"A\"][0][i].auto_ml.best_loss\n",
    "            _res_of.append(fs_of_mlg / n_folds)\n",
    "            _res_of.append(fs_of_mlm / n_folds)\n",
    "\n",
    "            ml_g_pred = treat_ind * dml_irm_automl_onfolds.predictions[\"ml_g1\"][:,0,0] + (1 - treat_ind) * dml_irm_automl_onfolds.predictions[\"ml_g0\"][:,0,0]\n",
    "            _res_of.append(mean_squared_error(y, ml_g_pred))\n",
    "            _res_of.append(log_loss(d, dml_irm_automl_onfolds.predictions[\"ml_m\"][:,0,0]))\n",
    "\n",
    "            # add this iteration to overall results\n",
    "            res_fullsample.append(_res_full)\n",
    "            res_splitsample.append(_res_split)\n",
    "            res_onfolds.append(_res_of)\n",
    "\n",
    "            # save current result\n",
    "            pd.DataFrame(res_fullsample, columns = [\"coef\",\"2.5%\",\"97.5%\",\"tune_loss_mll\",\"tune_loss_mlm\",\"fs_loss_mll\",\"fs_loss_mlm\"]).to_csv(res_path + f\"{t}_fullsample.csv\")\n",
    "            pd.DataFrame(res_splitsample, columns=[\"coef\",\"2.5%\",\"97.5%\",\"tune_loss_mll\",\"tune_loss_mlm\",\"fs_loss_mll\",\"fs_loss_mlm\"]).to_csv(res_path + f\"{t}_splitsample.csv\")\n",
    "            pd.DataFrame(res_onfolds, columns=[\"coef\",\"2.5%\",\"97.5%\",\"tune_loss_mll\",\"tune_loss_mlm\",\"fs_loss_mll\",\"fs_loss_mlm\"]).to_csv(res_path + f\"{t}_onfolds.csv\")  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "vscode": {
   "interpreter": {
    "hash": "8f33305f67a2cd4fce49cfe0fb8dea12a4f316415e2df00ee6a89784b5de5816"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
