{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97ef56e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import doubleml as dml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, log_loss\n",
    "from sklearn.linear_model import LassoCV, LogisticRegressionCV, Lasso, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from xgboost import XGBRegressor, XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bd9d18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.multiclass import unique_labels\n",
    "class LassoCVClassifier:\n",
    "    _estimator_type = 'classifier'\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.lasso = LassoCV(*args, **kwargs)\n",
    "\n",
    "    def set_params(self, **params):\n",
    "        self.lasso.set_params(**params)\n",
    "        return self\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        return self.lasso.get_params(deep)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.classes_ = unique_labels(y)\n",
    "        self.lasso.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, x):\n",
    "        preds = self.lasso.predict(x)\n",
    "        return np.c_[(1-preds),preds]\n",
    "    \n",
    "\n",
    "class LassoClassifier:\n",
    "    _estimator_type = 'classifier'\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.lasso = Lasso(*args, **kwargs)\n",
    "\n",
    "    def set_params(self, **params):\n",
    "        self.lasso.set_params(**params)\n",
    "        return self\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        return self.lasso.get_params(deep)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.classes_ = unique_labels(y)\n",
    "        self.lasso.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, x):\n",
    "        preds = self.lasso.predict(x)\n",
    "        return np.c_[(1-preds),preds]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c815fa5",
   "metadata": {},
   "source": [
    "## Lasso, Full Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aca34128",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 4\n",
    "no_iter = 100\n",
    "\n",
    "for sc in [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16]:\n",
    "    res_path = f\"../results/acic/irm/LassoCV/\"\n",
    "    res_fullsample = []\n",
    "    for k in range(no_iter):\n",
    "        # for saving each iteration\n",
    "        _res_full = []\n",
    "\n",
    "        # load data\n",
    "        df = pd.read_csv(f\"../dgp/acic/Scenario{sc}/CHDScenario{sc}DS{k+1}.csv\")           \n",
    "        y, d, X = df[\"Y\"], df[\"A\"], df.drop(columns=[\"Y\",\"A\"])\n",
    "\n",
    "        # full sample, tuning\n",
    "        ml_g = LassoCV(n_jobs=-1)\n",
    "        ml_g.fit(df.drop(columns=[\"Y\"]), y)\n",
    "        ml_g = Lasso(alpha=ml_g.alpha_)\n",
    "        ml_m = LassoCV(n_jobs=-1)\n",
    "        ml_m.fit(X, d)\n",
    "        ml_m = LassoClassifier(alpha=ml_m.alpha_)\n",
    "\n",
    "        # full sample, doubleml\n",
    "        np.random.seed(k)\n",
    "        obj_dml_data = dml.DoubleMLData(df,y_col='Y',d_cols='A')\n",
    "        dml_irm_automl = dml.DoubleMLIRM(obj_dml_data, ml_g = ml_g, ml_m = ml_m, n_folds = n_folds, trimming_threshold=0.025)\n",
    "        dml_irm_automl.fit(store_predictions=True)\n",
    "\n",
    "        _res_full.append(dml_irm_automl.summary[\"coef\"].values[0])\n",
    "        _res_full.append(dml_irm_automl.summary[\"2.5 %\"].values[0])\n",
    "        _res_full.append(dml_irm_automl.summary[\"97.5 %\"].values[0])\n",
    "        treat_ind = (df[\"A\"] == 1)\n",
    "        ml_g_pred = treat_ind * dml_irm_automl.predictions[\"ml_g1\"][:,0,0] + (1 - treat_ind) * dml_irm_automl.predictions[\"ml_g0\"][:,0,0]\n",
    "        _res_full.append(mean_squared_error(y, ml_g_pred))\n",
    "        _res_full.append(log_loss(d, dml_irm_automl.predictions[\"ml_m\"][:,0,0]))\n",
    "\n",
    "        # add this iteration to overall results\n",
    "        res_fullsample.append(_res_full)\n",
    "\n",
    "        # save current result\n",
    "        pd.DataFrame(res_fullsample, columns = [\"coef\",\"2.5%\",\"97.5%\",\"fs_loss_mll\",\"fs_loss_mlm\"]).to_csv(res_path + f\"Scenario{sc}_LassoCV_fullsample.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31315401",
   "metadata": {},
   "source": [
    "## Random Forest, default values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcd18cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "## with ACIC data\n",
    "n_folds = 4\n",
    "no_iter = 100\n",
    "\n",
    "for sc in [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16]:\n",
    "    res_path = f\"../results/acic/irm/RFdef/\"\n",
    "    res_fullsample = []\n",
    "    for k in range(no_iter):\n",
    "        # for saving each iteration\n",
    "        _res_full = []\n",
    "\n",
    "        # load data\n",
    "        df = pd.read_csv(f\"../dgp/acic/Scenario{sc}/CHDScenario{sc}DS{k+1}.csv\")           \n",
    "        y, d, X = df[\"Y\"], df[\"A\"], df.drop(columns=[\"Y\",\"A\"])\n",
    "\n",
    "        # full sample, tuning\n",
    "        ml_g = RandomForestRegressor(n_jobs=-1)\n",
    "        ml_m = RandomForestClassifier(n_jobs=-1)\n",
    "\n",
    "        # full sample, doubleml\n",
    "        np.random.seed(k)\n",
    "        obj_dml_data = dml.DoubleMLData(df,y_col='Y',d_cols='A')\n",
    "        dml_irm_automl = dml.DoubleMLIRM(obj_dml_data, ml_g = ml_g, ml_m = ml_m, n_folds = n_folds, trimming_threshold = 0.025)\n",
    "        dml_irm_automl.fit(store_predictions=True)\n",
    "\n",
    "        _res_full.append(dml_irm_automl.summary[\"coef\"].values[0])\n",
    "        _res_full.append(dml_irm_automl.summary[\"2.5 %\"].values[0])\n",
    "        _res_full.append(dml_irm_automl.summary[\"97.5 %\"].values[0])\n",
    "        treat_ind = (df[\"A\"] == 1)\n",
    "        ml_g_pred = treat_ind * dml_irm_automl.predictions[\"ml_g1\"][:,0,0] + (1 - treat_ind) * dml_irm_automl.predictions[\"ml_g0\"][:,0,0]\n",
    "        _res_full.append(mean_squared_error(y, ml_g_pred))\n",
    "        _res_full.append(log_loss(d, dml_irm_automl.predictions[\"ml_m\"][:,0,0]))\n",
    "\n",
    "        # add this iteration to overall results\n",
    "        res_fullsample.append(_res_full)\n",
    "\n",
    "        # save current result\n",
    "        pd.DataFrame(res_fullsample, columns = [\"coef\",\"2.5%\",\"97.5%\",\"fs_loss_mll\",\"fs_loss_mlm\"]).to_csv(res_path + f\"Scenario{sc}_RandomForestdefault.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64632d94",
   "metadata": {},
   "source": [
    "## Boosting, default values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b905e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "## with ACIC data\n",
    "n_folds = 4\n",
    "no_iter = 100\n",
    "\n",
    "for sc in [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16]:\n",
    "    res_path = f\"../results/acic/irm/XGBdef/\"\n",
    "    res_fullsample = []\n",
    "    for k in range(no_iter):\n",
    "        # for saving each iteration\n",
    "        _res_full = []\n",
    "\n",
    "        # load data\n",
    "        df = pd.read_csv(f\"../dgp/acic/Scenario{sc}/CHDScenario{sc}DS{k+1}.csv\")           \n",
    "        y, d, X = df[\"Y\"], df[\"A\"], df.drop(columns=[\"Y\",\"A\"])\n",
    "\n",
    "        # full sample, tuning\n",
    "        ml_g = XGBRegressor()\n",
    "        ml_m = XGBClassifier()\n",
    "\n",
    "        # full sample, doubleml\n",
    "        np.random.seed(k)\n",
    "        obj_dml_data = dml.DoubleMLData(df,y_col='Y',d_cols='A')\n",
    "        dml_irm_automl = dml.DoubleMLIRM(obj_dml_data, ml_g = ml_g, ml_m = ml_m, n_folds = n_folds, trimming_threshold = 0.025)\n",
    "        dml_irm_automl.fit(store_predictions=True)\n",
    "\n",
    "        _res_full.append(dml_irm_automl.summary[\"coef\"].values[0])\n",
    "        _res_full.append(dml_irm_automl.summary[\"2.5 %\"].values[0])\n",
    "        _res_full.append(dml_irm_automl.summary[\"97.5 %\"].values[0])\n",
    "        treat_ind = (df[\"A\"] == 1)\n",
    "        ml_g_pred = treat_ind * dml_irm_automl.predictions[\"ml_g1\"][:,0,0] + (1 - treat_ind) * dml_irm_automl.predictions[\"ml_g0\"][:,0,0]\n",
    "        _res_full.append(mean_squared_error(y, ml_g_pred))\n",
    "        _res_full.append(log_loss(d, dml_irm_automl.predictions[\"ml_m\"][:,0,0]))\n",
    "\n",
    "        # add this iteration to overall results\n",
    "        res_fullsample.append(_res_full)\n",
    "\n",
    "        # save current result\n",
    "        pd.DataFrame(res_fullsample, columns = [\"coef\",\"2.5%\",\"97.5%\",\"fs_loss_mll\",\"fs_loss_mlm\"]).to_csv(res_path + f\"Scenario{sc}_XGBoostdefault.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a8bb48",
   "metadata": {},
   "source": [
    "## Lasso, Tune on the folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3728bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "## with ACIC data\n",
    "n_folds = 4\n",
    "no_iter = 100\n",
    "\n",
    "for sc in [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16]:\n",
    "    res_path = f\"../results/acic/irm/LassoCV/\"\n",
    "    res_fullsample = []\n",
    "    for k in range(no_iter):\n",
    "        # for saving each iteration\n",
    "        _res_full = []\n",
    "\n",
    "        # load data\n",
    "        df = pd.read_csv(f\"../dgp/acic/Scenario{sc}/CHDScenario{sc}DS{k+1}.csv\")           \n",
    "        y, d, X = df[\"Y\"], df[\"A\"], df.drop(columns=[\"Y\",\"A\"])\n",
    "\n",
    "        # full sample, tuning\n",
    "        ml_g = LassoCV(n_jobs=-1)\n",
    "        ml_m = LassoCVClassifier(n_jobs=-1)\n",
    "\n",
    "        # full sample, doubleml\n",
    "        np.random.seed(k)\n",
    "        obj_dml_data = dml.DoubleMLData(df,y_col='Y',d_cols='A')\n",
    "        dml_irm_automl = dml.DoubleMLIRM(obj_dml_data, ml_g = ml_g, ml_m = ml_m, n_folds = n_folds, trimming_threshold=0.025)\n",
    "        dml_irm_automl.fit(store_predictions=True, store_models=True)\n",
    "\n",
    "        _res_full.append(dml_irm_automl.summary[\"coef\"].values[0])\n",
    "        _res_full.append(dml_irm_automl.summary[\"2.5 %\"].values[0])\n",
    "        _res_full.append(dml_irm_automl.summary[\"97.5 %\"].values[0])\n",
    "        treat_ind = (df[\"A\"] == 1)\n",
    "        ml_g_pred = treat_ind * dml_irm_automl.predictions[\"ml_g1\"][:,0,0] + (1 - treat_ind) * dml_irm_automl.predictions[\"ml_g0\"][:,0,0]\n",
    "        _res_full.append(mean_squared_error(y, ml_g_pred))\n",
    "        _res_full.append(log_loss(d, dml_irm_automl.predictions[\"ml_m\"][:,0,0]))\n",
    "\n",
    "        # add this iteration to overall results\n",
    "        res_fullsample.append(_res_full)\n",
    "\n",
    "        # save current result\n",
    "        pd.DataFrame(res_fullsample, columns = [\"coef\",\"2.5%\",\"97.5%\",\"fs_loss_mll\",\"fs_loss_mlm\"]).to_csv(res_path + f\"Scenario{sc}_LassoCV_onfolds.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4138c444",
   "metadata": {},
   "source": [
    "## Lasso, Split the sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5c142629",
   "metadata": {},
   "outputs": [],
   "source": [
    "## with ACIC data\n",
    "n_folds = 4\n",
    "no_iter = 100\n",
    "\n",
    "for sc in [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16]:\n",
    "    res_path = f\"../results/acic/irm/LassoCV/\"\n",
    "    res_fullsample = []\n",
    "    for k in range(no_iter):\n",
    "        # for saving each iteration\n",
    "        _res_full = []\n",
    "\n",
    "        # load data\n",
    "        df = pd.read_csv(f\"../dgp/acic/Scenario{sc}/CHDScenario{sc}DS{k+1}.csv\")      \n",
    "        df_tune, df_test = train_test_split(df, test_size= 0.5, random_state = 42)\n",
    "        y_tune, d_tune, X_tune = df_tune[\"Y\"], df_tune[\"A\"], df_tune.drop(columns=[\"Y\",\"A\"])\n",
    "\n",
    "        # full sample, tuning\n",
    "        lasso_g = LassoCV(n_jobs=-1)\n",
    "        lasso_g.fit(df_tune.drop(columns=[\"Y\"]), y_tune)\n",
    "        ml_g = Lasso(alpha=lasso_g.alpha_)\n",
    "        log_m = LassoCV(n_jobs=-1)\n",
    "        log_m.fit(X_tune, d_tune)\n",
    "        ml_m = LassoClassifier(alpha=log_m.alpha_)\n",
    "\n",
    "        # full sample, doubleml\n",
    "        np.random.seed(k)\n",
    "        obj_dml_data = dml.DoubleMLData(df_test,y_col='Y',d_cols='A')\n",
    "        dml_irm_automl = dml.DoubleMLIRM(obj_dml_data, ml_g = ml_g, ml_m = ml_m, n_folds = n_folds, trimming_threshold=0.025)\n",
    "        dml_irm_automl.fit(store_predictions=True, store_models=True)\n",
    "\n",
    "        _res_full.append(dml_irm_automl.summary[\"coef\"].values[0])\n",
    "        _res_full.append(dml_irm_automl.summary[\"2.5 %\"].values[0])\n",
    "        _res_full.append(dml_irm_automl.summary[\"97.5 %\"].values[0])\n",
    "        treat_ind = (df_test[\"A\"] == 1)\n",
    "        ml_g_pred = treat_ind * dml_irm_automl.predictions[\"ml_g1\"][:,0,0] + (1 - treat_ind) * dml_irm_automl.predictions[\"ml_g0\"][:,0,0]\n",
    "        _res_full.append(mean_squared_error(df_test[\"Y\"], ml_g_pred))\n",
    "        _res_full.append(log_loss(df_test[\"A\"], dml_irm_automl.predictions[\"ml_m\"][:,0,0]))\n",
    "\n",
    "        # add this iteration to overall results\n",
    "        res_fullsample.append(_res_full)\n",
    "\n",
    "        # save current result\n",
    "        pd.DataFrame(res_fullsample, columns = [\"coef\",\"2.5%\",\"97.5%\",\"fs_loss_mll\",\"fs_loss_mlm\"]).to_csv(res_path + f\"Scenario{sc}_LassoCV_splitsample.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
