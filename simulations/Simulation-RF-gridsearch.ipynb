{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import doubleml as dml\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, log_loss\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_l = {'max_depth': [4,5,6],\n",
    "        'n_estimators': [100],\n",
    "        'n_jobs': [-1]}\n",
    "grid_m = {'max_depth': [4,5,6],\n",
    "        'n_estimators': [100],\n",
    "        'n_jobs': [-1]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLR Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## with ACIC data\n",
    "n_folds = 4\n",
    "no_iter = 100\n",
    "\n",
    "for sc in [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16]:\n",
    "    res_path = f\"../results/acic/plr/RandomForest/Scenario{sc}_\"\n",
    "    res_fullsample = []\n",
    "    res_splitsample = []\n",
    "    res_onfolds = []\n",
    "    for k in range(no_iter):\n",
    "        print(k)\n",
    "        # for saving each iteration\n",
    "        _res_full = []\n",
    "        _res_split = []\n",
    "        _res_of = []\n",
    "        \n",
    "        # load data\n",
    "        df = pd.read_csv(f\"../dgp/acic/Scenario{sc}/CHDScenario{sc}DS{k+1}.csv\")           \n",
    "        y, d, X = df[\"Y\"], df[\"A\"], df.drop(columns=[\"Y\",\"A\"])\n",
    "    \n",
    "        # full sample, tuning\n",
    "        gs_l = GridSearchCV(RandomForestRegressor(), grid_l, n_jobs=-1, scoring=\"neg_mean_squared_error\")\n",
    "        gs_l.fit(X,y)\n",
    "        gs_m = GridSearchCV(RandomForestClassifier(), grid_m, n_jobs=-1, scoring=\"neg_log_loss\")\n",
    "        gs_m.fit(X,d)\n",
    "\n",
    "        ml_l = gs_l.best_estimator_\n",
    "        ml_m = gs_m.best_estimator_\n",
    "\n",
    "        # full sample, doubleml\n",
    "        np.random.seed(k)\n",
    "        obj_dml_data = dml.DoubleMLData(df,y_col='Y',d_cols='A')\n",
    "        dml_plr = dml.DoubleMLPLR(obj_dml_data, ml_l = ml_l, ml_m = ml_m, n_folds = n_folds)\n",
    "        dml_plr.fit(store_predictions=True)\n",
    "\n",
    "        _res_full.append(dml_plr.summary[\"coef\"].values[0])\n",
    "        _res_full.append(dml_plr.summary[\"2.5 %\"].values[0])\n",
    "        _res_full.append(dml_plr.summary[\"97.5 %\"].values[0])\n",
    "        _res_full.append(-1 * gs_l.best_score_)\n",
    "        _res_full.append(-1 * gs_m.best_score_)\n",
    "        _res_full.append(mean_squared_error(y, dml_plr.summary[\"coef\"].values[0] * d + dml_plr.predictions[\"ml_l\"][:,0,0]))\n",
    "        _res_full.append(mean_squared_error(y, dml_plr.predictions[\"ml_l\"][:,0,0]))\n",
    "        _res_full.append(log_loss(d, dml_plr.predictions[\"ml_m\"][:,0,0]))\n",
    "\n",
    "        # split sample, tuning\n",
    "        df_tune, df_test = train_test_split(df, test_size= 0.5, random_state = 42*k)\n",
    "        y_tune, d_tune, X_tune = df_tune[\"Y\"], df_tune[\"A\"], df_tune.drop(columns=[\"Y\",\"A\"])\n",
    "        \n",
    "        gs_l = GridSearchCV(RandomForestRegressor(), grid_l, n_jobs=-1, scoring=\"neg_mean_squared_error\")\n",
    "        gs_l.fit(X_tune,y_tune)\n",
    "        gs_m = GridSearchCV(RandomForestClassifier(), grid_m, n_jobs=-1, scoring=\"neg_log_loss\")\n",
    "        gs_m.fit(X_tune,d_tune)\n",
    "\n",
    "        ml_l = gs_l.best_estimator_\n",
    "        ml_m = gs_m.best_estimator_\n",
    "\n",
    "        # split sample, doubleml           \n",
    "        np.random.seed(2*k)\n",
    "        obj_dml_data = dml.DoubleMLData(df_test, y_col='Y', d_cols='A')\n",
    "        dml_plr_split = dml.DoubleMLPLR(obj_dml_data, ml_l = ml_l, ml_m = ml_m, n_folds = n_folds)\n",
    "        dml_plr_split.fit(store_predictions = True)\n",
    "\n",
    "        _res_split.append(dml_plr_split.summary[\"coef\"].values[0])\n",
    "        _res_split.append(dml_plr_split.summary[\"2.5 %\"].values[0])\n",
    "        _res_split.append(dml_plr_split.summary[\"97.5 %\"].values[0])\n",
    "        _res_split.append(-1 * gs_l.best_score_)\n",
    "        _res_split.append(-1 * gs_m.best_score_)\n",
    "        _res_split.append(mean_squared_error(df_test[\"Y\"], dml_plr_split.summary[\"coef\"].values[0] * df_test[\"A\"] +  dml_plr_split.predictions[\"ml_l\"][:,0,0]))\n",
    "        _res_split.append(mean_squared_error(df_test[\"Y\"], dml_plr_split.predictions[\"ml_l\"][:,0,0]))\n",
    "        _res_split.append(log_loss(df_test[\"A\"], dml_plr_split.predictions[\"ml_m\"][:,0,0]))\n",
    "\n",
    "        # on folds\n",
    "        ml_l = RandomForestRegressor()\n",
    "        ml_m = RandomForestClassifier()\n",
    "\n",
    "        obj_dml_data = dml.DoubleMLData(df,y_col='Y',d_cols='A')\n",
    "\n",
    "        np.random.seed(3*k)\n",
    "        dml_plr_onfolds = dml.DoubleMLPLR(obj_dml_data, ml_l = ml_l, ml_m = ml_m, n_folds = n_folds)\n",
    "        dml_plr_onfolds.tune({\"ml_l\": grid_l, \"ml_m\": grid_m}, tune_on_folds=True)\n",
    "        dml_plr_onfolds.fit(store_predictions=True, store_models = True)\n",
    "\n",
    "        _res_of.append(dml_plr_onfolds.summary[\"coef\"].values[0])\n",
    "        _res_of.append(dml_plr_onfolds.summary[\"2.5 %\"].values[0])\n",
    "        _res_of.append(dml_plr_onfolds.summary[\"97.5 %\"].values[0])\n",
    "        _res_of.append(np.nan)\n",
    "        _res_of.append(np.nan)\n",
    "        _res_of.append(mean_squared_error(y, dml_plr_onfolds.summary[\"coef\"].values[0] * d + dml_plr_onfolds.predictions[\"ml_l\"][:,0,0]))\n",
    "        _res_of.append(mean_squared_error(y, dml_plr_onfolds.predictions[\"ml_l\"][:,0,0]))\n",
    "        _res_of.append(log_loss(d, dml_plr_onfolds.predictions[\"ml_m\"][:,0,0]))\n",
    "        \n",
    "        # # add this iteration to overall results\n",
    "        res_fullsample.append(_res_full)\n",
    "        res_splitsample.append(_res_split)\n",
    "        res_onfolds.append(_res_of)\n",
    "\n",
    "        # save current result\n",
    "        pd.DataFrame(res_fullsample, columns = [\"coef\",\"2.5%\",\"97.5%\",\"tune_loss_mll\",\"tune_loss_mlm\",\"loss_Y\",\"fs_loss_mll\",\"fs_loss_mlm\"]).to_csv(res_path + f\"fullsample_v3.csv\")\n",
    "        pd.DataFrame(res_splitsample, columns=[\"coef\",\"2.5%\",\"97.5%\",\"tune_loss_mll\",\"tune_loss_mlm\",\"loss_Y\",\"fs_loss_mll\",\"fs_loss_mlm\"]).to_csv(res_path + f\"splitsample_v3.csv\")\n",
    "        pd.DataFrame(res_onfolds, columns=[\"coef\",\"2.5%\",\"97.5%\",\"tune_loss_mll\",\"tune_loss_mlm\",\"loss_Y\",\"fs_loss_mll\",\"fs_loss_mlm\"]).to_csv(res_path + f\"onfolds_v3.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IRM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## with ACIC data\n",
    "n_folds = 4\n",
    "no_iter = 100\n",
    "\n",
    "for sc in range(16):\n",
    "    sc+=1\n",
    "    res_path = f\"../results/acic/irm/RandomForest/Scenario{sc}_\"\n",
    "    res_fullsample = []\n",
    "    res_splitsample = []\n",
    "    res_onfolds = []\n",
    "    for k in range(no_iter):\n",
    "        # for saving each iteration\n",
    "        _res_full = []\n",
    "        _res_split = []\n",
    "        _res_of = []\n",
    "        \n",
    "        # load data\n",
    "        df = pd.read_csv(f\"../dgp/acic/Scenario{sc}/CHDScenario{sc}DS{k+1}.csv\")           \n",
    "        y, d, X = df[\"Y\"], df[\"A\"], df.drop(columns=[\"Y\",\"A\"])\n",
    "    \n",
    "        # full sample, tuning\n",
    "        gs_g = GridSearchCV(RandomForestRegressor(), grid_l, n_jobs=-1, scoring=\"neg_mean_squared_error\")\n",
    "        gs_g.fit(np.c_[X,d],y)\n",
    "        gs_m = GridSearchCV(RandomForestClassifier(), grid_m, n_jobs=-1, scoring=\"neg_log_loss\")\n",
    "        gs_m.fit(X,d)\n",
    "\n",
    "        ml_g = gs_g.best_estimator_\n",
    "        ml_m = gs_m.best_estimator_\n",
    "\n",
    "        # full sample, doubleml\n",
    "        np.random.seed(k)\n",
    "        obj_dml_data = dml.DoubleMLData(df,y_col='Y',d_cols='A')\n",
    "        dml_irm = dml.DoubleMLIRM(obj_dml_data, ml_g = ml_g, ml_m = ml_m, n_folds = n_folds)\n",
    "        dml_irm.fit(store_predictions=True)\n",
    "\n",
    "        _res_full.append(dml_irm.summary[\"coef\"].values[0])\n",
    "        _res_full.append(dml_irm.summary[\"2.5 %\"].values[0])\n",
    "        _res_full.append(dml_irm.summary[\"97.5 %\"].values[0])\n",
    "        _res_full.append(-1 * gs_g.best_score_)\n",
    "        _res_full.append(-1 * gs_m.best_score_)\n",
    "        treat_ind = (df[\"A\"] == 1)\n",
    "        ml_g_pred = treat_ind * dml_irm.predictions[\"ml_g1\"][:,0,0] + (1 - treat_ind) * dml_irm.predictions[\"ml_g0\"][:,0,0]\n",
    "        _res_full.append(mean_squared_error(y, ml_g_pred))\n",
    "        _res_full.append(log_loss(d, dml_irm.predictions[\"ml_m\"][:,0,0]))\n",
    "\n",
    "        # split sample, tuning\n",
    "        df_tune, df_test = train_test_split(df, test_size= 0.5, random_state = 42*k)\n",
    "        y_tune, d_tune, X_tune = df_tune[\"Y\"], df_tune[\"A\"], df_tune.drop(columns=[\"Y\",\"A\"])\n",
    "        \n",
    "        gs_g = GridSearchCV(RandomForestRegressor(), grid_l, n_jobs=-1, scoring=\"neg_mean_squared_error\")\n",
    "        gs_g.fit(np.c_[X_tune,d_tune],y_tune)\n",
    "        gs_m = GridSearchCV(RandomForestClassifier(), grid_m, n_jobs=-1, scoring=\"neg_log_loss\")\n",
    "        gs_m.fit(X_tune,d_tune)\n",
    "\n",
    "        ml_g = gs_g.best_estimator_\n",
    "        ml_m = gs_m.best_estimator_\n",
    "\n",
    "        # split sample, doubleml           \n",
    "        np.random.seed(2*k)\n",
    "        obj_dml_data = dml.DoubleMLData(df_test, y_col='Y', d_cols='A')\n",
    "        dml_irm_split = dml.DoubleMLIRM(obj_dml_data, ml_g = ml_g, ml_m = ml_m, n_folds = n_folds)\n",
    "        dml_irm_split.fit(store_predictions = True)\n",
    "\n",
    "        _res_split.append(dml_irm_split.summary[\"coef\"].values[0])\n",
    "        _res_split.append(dml_irm_split.summary[\"2.5 %\"].values[0])\n",
    "        _res_split.append(dml_irm_split.summary[\"97.5 %\"].values[0])\n",
    "        _res_split.append(-1 * gs_g.best_score_)\n",
    "        _res_split.append(-1 * gs_m.best_score_)\n",
    "        treat_ind = (df_test[\"A\"] == 1)\n",
    "        ml_g_pred = treat_ind * dml_irm_split.predictions[\"ml_g1\"][:,0,0] + (1 - treat_ind) * dml_irm_split.predictions[\"ml_g0\"][:,0,0]\n",
    "        _res_split.append(mean_squared_error(df_test[\"Y\"], ml_g_pred))\n",
    "        _res_split.append(log_loss(df_test[\"A\"], dml_irm_split.predictions[\"ml_m\"][:,0,0]))\n",
    "\n",
    "        # on folds\n",
    "        ml_l = RandomForestRegressor()\n",
    "        ml_m = RandomForestClassifier()\n",
    "\n",
    "        obj_dml_data = dml.DoubleMLData(df,y_col='Y',d_cols='A')\n",
    "\n",
    "        np.random.seed(3*k)\n",
    "        dml_irm_onfolds = dml.DoubleMLIRM(obj_dml_data, ml_g = ml_g, ml_m = ml_m, n_folds = n_folds)\n",
    "        dml_irm_onfolds.tune({\"ml_g\": grid_l, \"ml_m\": grid_m}, tune_on_folds=True)\n",
    "        dml_irm_onfolds.fit(store_predictions=True, store_models = True)\n",
    "\n",
    "        _res_of.append(dml_irm_onfolds.summary[\"coef\"].values[0])\n",
    "        _res_of.append(dml_irm_onfolds.summary[\"2.5 %\"].values[0])\n",
    "        _res_of.append(dml_irm_onfolds.summary[\"97.5 %\"].values[0])\n",
    "        _res_of.append(np.nan)\n",
    "        _res_of.append(np.nan)\n",
    "        treat_ind = (df[\"A\"] == 1)\n",
    "        ml_g_pred = treat_ind * dml_irm_onfolds.predictions[\"ml_g1\"][:,0,0] + (1 - treat_ind) * dml_irm_onfolds.predictions[\"ml_g0\"][:,0,0]\n",
    "        _res_of.append(mean_squared_error(y, ml_g_pred))\n",
    "        _res_of.append(log_loss(d, dml_irm_onfolds.predictions[\"ml_m\"][:,0,0]))\n",
    "        \n",
    "        # # add this iteration to overall results\n",
    "        res_fullsample.append(_res_full)\n",
    "        res_splitsample.append(_res_split)\n",
    "        res_onfolds.append(_res_of)\n",
    "\n",
    "        # save current result\n",
    "        pd.DataFrame(res_fullsample, columns = [\"coef\",\"2.5%\",\"97.5%\",\"tune_loss_mlg\",\"tune_loss_mlm\",\"fs_loss_mlg\",\"fs_loss_mlm\"]).to_csv(res_path + f\"fullsample.csv\")\n",
    "        pd.DataFrame(res_splitsample, columns=[\"coef\",\"2.5%\",\"97.5%\",\"tune_loss_mlg\",\"tune_loss_mlm\",\"fs_loss_mlg\",\"fs_loss_mlm\"]).to_csv(res_path + f\"splitsample.csv\")\n",
    "        pd.DataFrame(res_onfolds, columns=[\"coef\",\"2.5%\",\"97.5%\",\"tune_loss_mlg\",\"tune_loss_mlm\",\"fs_loss_mlg\",\"fs_loss_mlm\"]).to_csv(res_path + f\"onfolds.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
