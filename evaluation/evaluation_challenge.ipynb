{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix C: ACIC Challenge Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: As we do not have permission of all participants, we do not publish the file with full ACIC results.\n",
    "Please contact us for replication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load results of our simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sc</th>\n",
       "      <th>rep</th>\n",
       "      <th>model</th>\n",
       "      <th>learner</th>\n",
       "      <th>scheme</th>\n",
       "      <th>coef</th>\n",
       "      <th>confint</th>\n",
       "      <th>bias</th>\n",
       "      <th>rbias</th>\n",
       "      <th>rstd</th>\n",
       "      <th>rrmse</th>\n",
       "      <th>predict_y</th>\n",
       "      <th>comb_loss</th>\n",
       "      <th>rrmse-1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>plr</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>fullsample</td>\n",
       "      <td>0.286102</td>\n",
       "      <td>1</td>\n",
       "      <td>0.086102</td>\n",
       "      <td>1.000627</td>\n",
       "      <td>1.090694</td>\n",
       "      <td>1.095024</td>\n",
       "      <td>4.722745</td>\n",
       "      <td>3.709074</td>\n",
       "      <td>0.095024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>plr</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>fullsample</td>\n",
       "      <td>0.33644</td>\n",
       "      <td>1</td>\n",
       "      <td>0.13644</td>\n",
       "      <td>1.000627</td>\n",
       "      <td>1.090694</td>\n",
       "      <td>1.095024</td>\n",
       "      <td>4.892763</td>\n",
       "      <td>4.057695</td>\n",
       "      <td>0.095024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>plr</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>fullsample</td>\n",
       "      <td>0.090525</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.109475</td>\n",
       "      <td>1.000627</td>\n",
       "      <td>1.090694</td>\n",
       "      <td>1.095024</td>\n",
       "      <td>5.130473</td>\n",
       "      <td>3.955124</td>\n",
       "      <td>0.095024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>plr</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>fullsample</td>\n",
       "      <td>0.370382</td>\n",
       "      <td>1</td>\n",
       "      <td>0.170382</td>\n",
       "      <td>1.000627</td>\n",
       "      <td>1.090694</td>\n",
       "      <td>1.095024</td>\n",
       "      <td>5.114704</td>\n",
       "      <td>3.96432</td>\n",
       "      <td>0.095024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>plr</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>fullsample</td>\n",
       "      <td>0.233294</td>\n",
       "      <td>1</td>\n",
       "      <td>0.033294</td>\n",
       "      <td>1.000627</td>\n",
       "      <td>1.090694</td>\n",
       "      <td>1.095024</td>\n",
       "      <td>5.559756</td>\n",
       "      <td>4.272133</td>\n",
       "      <td>0.095024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sc rep model learner      scheme      coef confint      bias     rbias  \\\n",
       "0  1   0   plr   Lasso  fullsample  0.286102       1  0.086102  1.000627   \n",
       "1  1   1   plr   Lasso  fullsample   0.33644       1   0.13644  1.000627   \n",
       "2  1   2   plr   Lasso  fullsample  0.090525       1 -0.109475  1.000627   \n",
       "3  1   3   plr   Lasso  fullsample  0.370382       1  0.170382  1.000627   \n",
       "4  1   4   plr   Lasso  fullsample  0.233294       1  0.033294  1.000627   \n",
       "\n",
       "       rstd     rrmse predict_y comb_loss   rrmse-1  \n",
       "0  1.090694  1.095024  4.722745  3.709074  0.095024  \n",
       "1  1.090694  1.095024  4.892763  4.057695  0.095024  \n",
       "2  1.090694  1.095024  5.130473  3.955124  0.095024  \n",
       "3  1.090694  1.095024  5.114704   3.96432  0.095024  \n",
       "4  1.090694  1.095024  5.559756  4.272133  0.095024  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schemes = [\"fullsample\", \"splitsample\", \"onfolds\"]\n",
    "models = [\"plr\", \"irm\"]\n",
    "learners = [\"Lasso\", \"Random Forest\", \"XGBoost\", \"FLAML\"]\n",
    "scenarios = range(16)\n",
    "oracle_df = pd.read_csv(\"../results/acic/oracle.csv\", delimiter=\";\")\n",
    "res = []\n",
    "for sc in scenarios:\n",
    "    true_theta = oracle_df.loc[oracle_df.DGPid==(sc+1),\"psi0.ATE\"].values[0]\n",
    "    oracle_mse = oracle_df.loc[oracle_df.DGPid==(sc+1),\"MSE\"].values[0]\n",
    "    oracle_bias = oracle_df.loc[oracle_df.DGPid==(sc+1),\"bias\"].values[0]\n",
    "    oracle_std = oracle_df.loc[oracle_df.DGPid==(sc+1),\"sd\"].values[0]\n",
    "    for model in models:\n",
    "        for learner in learners:\n",
    "            if learner == \"LinearModels\":\n",
    "                schemes = [\"fullsample\"]\n",
    "            else: \n",
    "                schemes = [\"fullsample\", \"splitsample\", \"onfolds\"]\n",
    "            for scheme in schemes:\n",
    "                paths = {\n",
    "                    \"Lasso\": f\"../results/acic/{model}/LassoCV/Scenario{sc+1}_LassoCV_{scheme}.csv\",\n",
    "                    \"Random Forest\":  f\"../results/acic/{model}/RandomForest/Scenario{sc+1}_{scheme}.csv\",\n",
    "                    \"XGBoost\": f\"../results/acic/{model}/XGBoost/Scenario{sc+1}_{scheme}.csv\",\n",
    "                    \"FLAML\": f\"../results/acic/{model}/Scenario{sc+1}/60_{scheme}.csv\",\n",
    "                    \"LinearModels\": f\"../results/acic/{model}/LinearModels/Scenario{sc+1}_LinearModels_{scheme}.csv\",\n",
    "                        }\n",
    "                load_df = pd.read_csv(paths[learner])\n",
    "                rep = load_df[\"Unnamed: 0\"]\n",
    "                coef = load_df[\"coef\"].values\n",
    "                confint = ((load_df[\"2.5%\"] < true_theta) & (load_df[\"97.5%\"] > true_theta)).astype(\"int\").values\n",
    "                bias = coef - true_theta\n",
    "                rrmse = np.sqrt(np.mean(np.square(bias))) / np.sqrt(oracle_mse)\n",
    "                rbias = np.abs(np.mean(coef - true_theta)/oracle_bias)\n",
    "                rstd = np.std(coef)/oracle_std\n",
    "                if model == \"irm\":\n",
    "                    try:\n",
    "                        predict_y = load_df[\"fs_loss_mlg\"]\n",
    "                        comb_loss = load_df[\"fs_loss_mlg\"] * load_df[\"fs_loss_mlm\"]\n",
    "                    except:\n",
    "                        predict_y = load_df[\"fs_loss_mll\"]\n",
    "                        comb_loss = load_df[\"fs_loss_mll\"] * load_df[\"fs_loss_mlm\"]\n",
    "                if model == \"plr\":\n",
    "                    comb_loss = (load_df[\"fs_loss_mll\"] + load_df[\"fs_loss_mlm\"]) * load_df[\"fs_loss_mlm\"]\n",
    "                    predict_y = load_df[\"loss_Y\"]\n",
    "\n",
    "                res.append(pd.DataFrame([np.repeat(sc+1,100), rep, np.repeat(model,100),np.repeat(learner,100),np.repeat(scheme,100),\n",
    "                                         coef, confint, bias, np.repeat(rbias,100), np.repeat(rstd,100), np.repeat(rrmse,100), predict_y, comb_loss], \n",
    "                                         index=[\"sc\", \"rep\", \"model\", \"learner\", \"scheme\", \"coef\", \"confint\", \"bias\", \"rbias\", \"rstd\", \"rrmse\", \"predict_y\", \"comb_loss\"]).transpose())\n",
    "df = pd.concat((res))\n",
    "df[\"rrmse-1\"] = df.rrmse.values -1\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the results of the default tuned learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sc</th>\n",
       "      <th>rep</th>\n",
       "      <th>model</th>\n",
       "      <th>learner</th>\n",
       "      <th>coef</th>\n",
       "      <th>confint</th>\n",
       "      <th>bias</th>\n",
       "      <th>rbias</th>\n",
       "      <th>rstd</th>\n",
       "      <th>rrmse</th>\n",
       "      <th>predict_y</th>\n",
       "      <th>comb_loss</th>\n",
       "      <th>rrmse-1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>plr</td>\n",
       "      <td>RF untuned</td>\n",
       "      <td>0.275805</td>\n",
       "      <td>1</td>\n",
       "      <td>0.075805</td>\n",
       "      <td>0.328216</td>\n",
       "      <td>1.095087</td>\n",
       "      <td>1.094198</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.98525</td>\n",
       "      <td>0.094198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>plr</td>\n",
       "      <td>RF untuned</td>\n",
       "      <td>0.344077</td>\n",
       "      <td>1</td>\n",
       "      <td>0.144077</td>\n",
       "      <td>0.328216</td>\n",
       "      <td>1.095087</td>\n",
       "      <td>1.094198</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.238201</td>\n",
       "      <td>0.094198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>plr</td>\n",
       "      <td>RF untuned</td>\n",
       "      <td>0.077935</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.122065</td>\n",
       "      <td>0.328216</td>\n",
       "      <td>1.095087</td>\n",
       "      <td>1.094198</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.196909</td>\n",
       "      <td>0.094198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>plr</td>\n",
       "      <td>RF untuned</td>\n",
       "      <td>0.44003</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24003</td>\n",
       "      <td>0.328216</td>\n",
       "      <td>1.095087</td>\n",
       "      <td>1.094198</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.353869</td>\n",
       "      <td>0.094198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>plr</td>\n",
       "      <td>RF untuned</td>\n",
       "      <td>0.162769</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.037231</td>\n",
       "      <td>0.328216</td>\n",
       "      <td>1.095087</td>\n",
       "      <td>1.094198</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.472103</td>\n",
       "      <td>0.094198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sc rep model     learner      coef confint      bias     rbias      rstd  \\\n",
       "0  1   0   plr  RF untuned  0.275805       1  0.075805  0.328216  1.095087   \n",
       "1  1   1   plr  RF untuned  0.344077       1  0.144077  0.328216  1.095087   \n",
       "2  1   2   plr  RF untuned  0.077935       1 -0.122065  0.328216  1.095087   \n",
       "3  1   3   plr  RF untuned   0.44003       1   0.24003  0.328216  1.095087   \n",
       "4  1   4   plr  RF untuned  0.162769       1 -0.037231  0.328216  1.095087   \n",
       "\n",
       "      rrmse predict_y comb_loss   rrmse-1  \n",
       "0  1.094198       NaN   3.98525  0.094198  \n",
       "1  1.094198       NaN  4.238201  0.094198  \n",
       "2  1.094198       NaN  4.196909  0.094198  \n",
       "3  1.094198       NaN  4.353869  0.094198  \n",
       "4  1.094198       NaN  4.472103  0.094198  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = [\"plr\", \"irm\"]\n",
    "learners = [\"RF untuned\", \"XGB untuned\"]\n",
    "scenarios = range(16)\n",
    "oracle_df = pd.read_csv(\"../results/acic/oracle.csv\", delimiter=\";\")\n",
    "res = []\n",
    "for sc in scenarios:\n",
    "    true_theta = oracle_df.loc[oracle_df.DGPid==(sc+1),\"psi0.ATE\"].values[0]\n",
    "    oracle_mse = oracle_df.loc[oracle_df.DGPid==(sc+1),\"MSE\"].values[0]\n",
    "    oracle_bias = oracle_df.loc[oracle_df.DGPid==(sc+1),\"bias\"].values[0]\n",
    "    oracle_std = oracle_df.loc[oracle_df.DGPid==(sc+1),\"sd\"].values[0]\n",
    "    for model in models:\n",
    "        for learner in learners:\n",
    "            paths = {\n",
    "                \"RF untuned\": f\"../results/acic/{model}/RFdef/Scenario{sc+1}_RandomForestdefault.csv\",\n",
    "                \"XGB untuned\": f\"../results/acic/{model}/XGBdef/Scenario{sc+1}_XGBoostdefault.csv\",\n",
    "                    }\n",
    "            load_df = pd.read_csv(paths[learner])\n",
    "            rep = load_df[\"Unnamed: 0\"]\n",
    "            coef = load_df[\"coef\"].values\n",
    "            confint = ((load_df[\"2.5%\"] < true_theta) & (load_df[\"97.5%\"] > true_theta)).astype(\"int\").values\n",
    "            bias = coef - true_theta\n",
    "            rrmse = np.sqrt(np.mean(np.square(bias))) / np.sqrt(oracle_mse)\n",
    "            rbias = np.abs(np.mean(coef - true_theta)/oracle_bias)\n",
    "            rstd = np.std(coef)/oracle_std\n",
    "            if model == \"irm\":\n",
    "                try:\n",
    "                    predict_y = load_df[\"fs_loss_mlg\"]\n",
    "                    comb_loss = load_df[\"fs_loss_mlg\"] * load_df[\"fs_loss_mlm\"]\n",
    "                except:\n",
    "                    predict_y = load_df[\"fs_loss_mll\"]\n",
    "                    comb_loss = load_df[\"fs_loss_mll\"] * load_df[\"fs_loss_mlm\"]\n",
    "            if model == \"plr\":\n",
    "                comb_loss = (load_df[\"fs_loss_mll\"] + load_df[\"fs_loss_mlm\"]) * load_df[\"fs_loss_mlm\"]\n",
    "                try:\n",
    "                    predict_y = load_df[\"loss_Y\"]\n",
    "                except:\n",
    "                    predict_y = np.repeat(np.nan,100)\n",
    "\n",
    "            res.append(pd.DataFrame([np.repeat(sc+1,100), rep, np.repeat(model,100),np.repeat(learner,100),\n",
    "                                        coef, confint, bias, np.repeat(rbias,100), np.repeat(rstd,100), np.repeat(rrmse,100), predict_y, comb_loss], \n",
    "                                        index=[\"sc\", \"rep\", \"model\", \"learner\", \"coef\", \"confint\", \"bias\", \"rbias\", \"rstd\", \"rrmse\", \"predict_y\", \"comb_loss\"]).transpose())\n",
    "default_df = pd.concat((res))\n",
    "default_df[\"rrmse-1\"] = default_df.rrmse.values -1\n",
    "default_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the results of all ACIC 2019 teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios=range(16)\n",
    "challenge_results = pd.read_csv(\"../results/acic/results_challenge.csv\").drop(columns=[\"Unnamed: 0\"])\n",
    "challenge_results = challenge_results.loc[challenge_results[\"Y.cont\"]==1]\n",
    "for sc in scenarios:\n",
    "    challenge_results.loc[challenge_results.DGPid==sc+1,\"RRMSE\"] = challenge_results.loc[challenge_results.DGPid==sc+1,\"rMSE\"] / np.sqrt(oracle_df.loc[oracle_df.DGPid==(sc+1),\"MSE\"].values[0])\n",
    "    challenge_results.loc[challenge_results.DGPid==sc+1,\"rel.bias\"] = np.abs(challenge_results.loc[challenge_results.DGPid==sc+1,\"bias\"] / oracle_df.loc[oracle_df.DGPid==(sc+1),\"bias\"].values[0])\n",
    "    challenge_results.loc[challenge_results.DGPid==sc+1,\"rel.sd\"] = np.abs(challenge_results.loc[challenge_results.DGPid==sc+1,\"sd\"] / oracle_df.loc[oracle_df.DGPid==(sc+1),\"sd\"].values[0])\n",
    "challenge_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we introduce different aggregations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_strategy(strategy_df, name):\n",
    "    scenarios=range(16)\n",
    "    res = []\n",
    "    for sc in scenarios:\n",
    "        true_theta = oracle_df.loc[oracle_df.DGPid==(sc+1),\"psi0.ATE\"].values[0]\n",
    "        oracle_mse = oracle_df.loc[oracle_df.DGPid==(sc+1),\"MSE\"].values[0]\n",
    "        oracle_bias = oracle_df.loc[oracle_df.DGPid==(sc+1),\"bias\"].values[0]\n",
    "        oracle_std = oracle_df.loc[oracle_df.DGPid==(sc+1),\"sd\"].values[0]\n",
    "        sub_df = strategy_df.loc[strategy_df.sc==(sc+1)]\n",
    "        bias = sub_df.coef - true_theta\n",
    "        res.append([np.sqrt(np.mean(np.square(bias)))/np.sqrt(oracle_mse), np.abs(np.mean(bias)/oracle_bias), sub_df.confint.mean(),sub_df.coef.std()/oracle_std])\n",
    "    res_strat = pd.DataFrame(res, columns=[\"RRMSE\",\"rel.bias\",\"coverage\",\"rel.sd\"])\n",
    "    res_strat[\"DGPid\"] = res_strat.index + 1\n",
    "    res_strat[\"fname\"] = np.repeat(name, 16)\n",
    "    return res_strat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strategy 1: Select Model by lower median of `predict_y` (MSE on Y), then select learner / scheme by lowest `comb_loss`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df1 = df.groupby(['sc', 'rep', 'model']).agg({'predict_y': 'median'}).reset_index()\n",
    "idx = grouped_df1.groupby(['sc', 'rep'])['predict_y'].idxmin()\n",
    "filtered_df1 = grouped_df1.loc[idx]\n",
    "filtered_df1 = filtered_df1.merge(df, on=[\"sc\",\"rep\",\"model\"], validate=\"one_to_many\")\n",
    "grouped_df2 = filtered_df1.groupby(['sc', 'rep', 'learner', 'scheme','model']).agg({'comb_loss': 'min'}).reset_index()\n",
    "idx = grouped_df2.groupby(['sc', 'rep'])['comb_loss'].idxmin()\n",
    "filtered_df2 = grouped_df2.loc[idx]\n",
    "final_df = pd.merge(filtered_df2.drop(columns=[\"comb_loss\"]), df, on=[\"sc\", \"rep\", \"model\", \"scheme\", \"learner\"], how=\"left\", validate=\"one_to_one\")\n",
    "res_strat1 = evaluate_strategy(final_df, \"DoubleML\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Always use FLAML & Fullsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df1 = df.loc[(df.scheme==\"fullsample\") & (df.learner==\"FLAML\")].groupby(['sc', 'rep', 'model']).agg({'predict_y': 'median'}).reset_index()\n",
    "idx = grouped_df1.groupby(['sc', 'rep'])['predict_y'].idxmin()\n",
    "filtered_df1 = grouped_df1.loc[idx]\n",
    "filtered_df1 = filtered_df1.merge(df, on=[\"sc\",\"rep\",\"model\"], validate=\"one_to_many\")\n",
    "grouped_df2 = filtered_df1.groupby(['sc', 'rep', 'learner', 'scheme','model']).agg({'comb_loss': 'min'}).reset_index()\n",
    "idx = grouped_df2.groupby(['sc', 'rep'])['comb_loss'].idxmin()\n",
    "filtered_df2 = grouped_df2.loc[idx]\n",
    "final_df = pd.merge(filtered_df2.drop(columns=[\"comb_loss\"]), df, on=[\"sc\", \"rep\", \"model\", \"scheme\", \"learner\"], how=\"left\", validate=\"one_to_one\")\n",
    "res_strat2 = evaluate_strategy(final_df, \"Only FLAML FS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use IRM and default RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df2 = default_df.loc[(default_df.learner==\"RF untuned\") & (default_df.model==\"irm\")]\n",
    "res_strat3 = evaluate_strategy(final_df2, \"RF default\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregate Absolute Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  RRMSE     rel.bias  coverage    rel.sd\n",
      "fname                                                   \n",
      "BART           2.257287  1628.814601  0.750000  1.244940\n",
      "BART_TMLE      2.192713  1301.510278  0.811875  1.356422\n",
      "DoubleML       2.932048  1372.111140  0.813750  2.407602\n",
      "Only FLAML FS  2.971526  1457.126124  0.815000  2.441941\n",
      "RF default     9.256483  1735.088988  0.665000  2.559791\n",
      "Std            3.428350  1105.027786  0.821875  2.509488\n",
      "eb             3.567365   988.042630  0.850625  2.748774\n"
     ]
    }
   ],
   "source": [
    "extended_res = pd.concat((challenge_results, res_strat1, res_strat2, res_strat3))\n",
    "print(extended_res.loc[extended_res.fname.isin([\"DoubleML\",\"Only FLAML FS\", \"RF default\", \"BART\", \"Std\", \"BART_TMLE\", \"eb\"])].groupby([\"fname\"])[[\"RRMSE\", \"rel.bias\",\"coverage\", \"rel.sd\"]].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scores for RRMSE, Bias and Standard Deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RRMSE</th>\n",
       "      <th>rel.bias</th>\n",
       "      <th>rel.sd</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fname</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BART</th>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BART_TMLE</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DoubleML</th>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Only FLAML FS</th>\n",
       "      <td>13.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF default</th>\n",
       "      <td>16.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Std</th>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eb</th>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               RRMSE  rel.bias  rel.sd\n",
       "fname                                 \n",
       "BART             3.0      11.0     1.0\n",
       "BART_TMLE        1.0       2.0     4.0\n",
       "DoubleML        11.0      10.0    16.0\n",
       "Only FLAML FS   13.0      15.0    17.0\n",
       "RF default      16.0      17.0    12.0\n",
       "Std              9.0       9.0    11.0\n",
       "eb              15.0       1.0    21.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = np.array([1/i for i in np.arange(1,13,1)] + [0] + [1/i for i in np.arange(-12,0,1)])\n",
    "extended_res = pd.concat((challenge_results, res_strat1, res_strat2, res_strat3))\n",
    "extended_res[\"rel.coverage\"] = np.abs(extended_res.coverage - 0.95)\n",
    "scores_df = pd.DataFrame()\n",
    "for metric in [\"RRMSE\",\"rel.bias\",\"rel.sd\"]:\n",
    "    sorted_res = extended_res.sort_values(by=[\"DGPid\", metric])\n",
    "    sorted_res[\"score\"] = np.tile(score, 16)\n",
    "    scores_df[metric] = sorted_res.groupby(\"fname\")[\"score\"].sum()\n",
    "scores_df.rank(ascending=False, method=\"min\").loc[scores_df.index.isin([\"DoubleML\",\"Only FLAML FS\", \"RF default\", \"BART\", \"Std\", \"BART_TMLE\", \"eb\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scores for Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fname\n",
       "DoubleML         14.0\n",
       "Only FLAML FS     8.0\n",
       "RF default       20.0\n",
       "BART             11.0\n",
       "Std               4.0\n",
       "BART_TMLE         2.0\n",
       "eb                7.0\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df[\"rel.coverage\"] = np.zeros_like(scores_df.RRMSE)\n",
    "score_helper = pd.DataFrame(score)\n",
    "score_helper[\"index\"] = np.arange(1,26)\n",
    "extended_res.set_index(\"fname\").groupby([\"DGPid\"])[\"rel.coverage\"].rank(\"min\").reset_index().merge(score_helper, left_on=\"rel.coverage\", right_on=\"index\").groupby(\"fname\")[0].sum().rank(ascending=False, method=\"min\")[[\"DoubleML\",\"Only FLAML FS\", \"RF default\", \"BART\", \"Std\", \"BART_TMLE\", \"eb\"]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dml05",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
